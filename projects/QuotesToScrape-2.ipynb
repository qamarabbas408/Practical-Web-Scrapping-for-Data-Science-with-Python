{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Quotes to Scrape</h2>\n",
    "here we will scrape <a> http://quotes.toscrape.com</a> for author and quotes information. We will store this data in SQLiteDatabase and instead using records libray we will be using dataset libray.<br>\n",
    "<i>pip install dataset</i><br><br>\n",
    "<b>Dataset library</b><br>\n",
    "Although managing data in relational databases has plenty of benefits, they’re rarely used in day-to-day work with small to medium scale datasets. But why is that? Why do we see an awful lot of data stored in static files in CSV or JSON format, even though they are hard to query and update incrementally? And in Python, a database isn’t the simplest solution for storing a bunch of structured data. This is what dataset is going to change! <b>dataset</b> provides a simple abstraction layer that removes most direct SQL statements without the necessity for a full ORM model - essentially, databases can be used like a JSON file or NoSQL store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now scraping page: http://quotes.toscrape.com/\n",
      "Now scraping page: http://quotes.toscrape.com/page/2/\n",
      "Now scraping page: http://quotes.toscrape.com/page/3/\n",
      "Now scraping page: http://quotes.toscrape.com/page/4/\n",
      "Now scraping page: http://quotes.toscrape.com/page/5/\n",
      "Now scraping page: http://quotes.toscrape.com/page/6/\n",
      "Now scraping page: http://quotes.toscrape.com/page/7/\n",
      "Now scraping page: http://quotes.toscrape.com/page/8/\n",
      "Now scraping page: http://quotes.toscrape.com/page/9/\n",
      "Now scraping page: http://quotes.toscrape.com/page/10/\n",
      "Now scraping author: http://quotes.toscrape.com/author/Harper-Lee\n",
      "Now scraping author: http://quotes.toscrape.com/author/Helen-Keller\n",
      "Now scraping author: http://quotes.toscrape.com/author/Jimi-Hendrix\n",
      "Now scraping author: http://quotes.toscrape.com/author/Ralph-Waldo-Emerson\n",
      "Now scraping author: http://quotes.toscrape.com/author/Bob-Marley\n",
      "Now scraping author: http://quotes.toscrape.com/author/Thomas-A-Edison\n",
      "Now scraping author: http://quotes.toscrape.com/author/Jim-Henson\n",
      "Now scraping author: http://quotes.toscrape.com/author/Pablo-Neruda\n",
      "Now scraping author: http://quotes.toscrape.com/author/Martin-Luther-King-Jr\n",
      "Now scraping author: http://quotes.toscrape.com/author/Haruki-Murakami\n",
      "Now scraping author: http://quotes.toscrape.com/author/Friedrich-Nietzsche\n",
      "Now scraping author: http://quotes.toscrape.com/author/J-R-R-Tolkien\n",
      "Now scraping author: http://quotes.toscrape.com/author/Albert-Einstein\n",
      "Now scraping author: http://quotes.toscrape.com/author/Jorge-Luis-Borges\n",
      "Now scraping author: http://quotes.toscrape.com/author/James-Baldwin\n",
      "Now scraping author: http://quotes.toscrape.com/author/Andre-Gide\n",
      "Now scraping author: http://quotes.toscrape.com/author/Charles-M-Schulz\n",
      "Now scraping author: http://quotes.toscrape.com/author/Terry-Pratchett\n",
      "Now scraping author: http://quotes.toscrape.com/author/J-D-Salinger\n",
      "Now scraping author: http://quotes.toscrape.com/author/Dr-Seuss\n",
      "Now scraping author: http://quotes.toscrape.com/author/William-Nicholson\n",
      "Now scraping author: http://quotes.toscrape.com/author/Elie-Wiesel\n",
      "Now scraping author: http://quotes.toscrape.com/author/Ernest-Hemingway\n",
      "Now scraping author: http://quotes.toscrape.com/author/George-Eliot\n",
      "Now scraping author: http://quotes.toscrape.com/author/George-Bernard-Shaw\n",
      "Now scraping author: http://quotes.toscrape.com/author/Suzanne-Collins\n",
      "Now scraping author: http://quotes.toscrape.com/author/George-R-R-Martin\n",
      "Now scraping author: http://quotes.toscrape.com/author/Eleanor-Roosevelt\n",
      "Now scraping author: http://quotes.toscrape.com/author/Allen-Saunders\n",
      "Now scraping author: http://quotes.toscrape.com/author/George-Carlin\n",
      "Now scraping author: http://quotes.toscrape.com/author/Alexandre-Dumas-fils\n",
      "Now scraping author: http://quotes.toscrape.com/author/Mark-Twain\n",
      "Now scraping author: http://quotes.toscrape.com/author/E-E-Cummings\n",
      "Now scraping author: http://quotes.toscrape.com/author/Douglas-Adams\n",
      "Now scraping author: http://quotes.toscrape.com/author/Jane-Austen\n",
      "Now scraping author: http://quotes.toscrape.com/author/Garrison-Keillor\n",
      "Now scraping author: http://quotes.toscrape.com/author/Stephenie-Meyer\n",
      "Now scraping author: http://quotes.toscrape.com/author/Ayn-Rand\n",
      "Now scraping author: http://quotes.toscrape.com/author/J-M-Barrie\n",
      "Now scraping author: http://quotes.toscrape.com/author/W-C-Fields\n",
      "Now scraping author: http://quotes.toscrape.com/author/J-K-Rowling\n",
      "Now scraping author: http://quotes.toscrape.com/author/Marilyn-Monroe\n",
      "Now scraping author: http://quotes.toscrape.com/author/Alfred-Tennyson\n",
      "Now scraping author: http://quotes.toscrape.com/author/John-Lennon\n",
      "Now scraping author: http://quotes.toscrape.com/author/Mother-Teresa\n",
      "Now scraping author: http://quotes.toscrape.com/author/Madeleine-LEngle\n",
      "Now scraping author: http://quotes.toscrape.com/author/Steve-Martin\n",
      "Now scraping author: http://quotes.toscrape.com/author/Khaled-Hosseini\n",
      "Now scraping author: http://quotes.toscrape.com/author/Charles-Bukowski\n",
      "Now scraping author: http://quotes.toscrape.com/author/C-S-Lewis\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import dataset\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "db = dataset.connect('sqlite:///C://Users//Qamar Abbas//Desktop//Learning//pws4ds//sqlite-databases//quotes_scrape.db')\n",
    "authors_seen = set()\n",
    "\n",
    "def scrape_quotes(html_soup):\n",
    "    for quote in html_soup.select('div.quote'):\n",
    "        quote_text = quote.find(class_='text').get_text(strip=True)\n",
    "        quote_author_url = clean_url(quote.find(class_='author').find_next_sibling('a').get('href'))\n",
    "        #list of tags\n",
    "        quote_tag_urls = [\n",
    "            clean_url(a.get('href'))for a in quote.find_all('a', class_='tag')\n",
    "            ]\n",
    "        authors_seen.add(quote_author_url)\n",
    "        \n",
    "        #dataset creates a table quotes and inserts data as dictionary. Here key represents colmun name \n",
    "        #creates id column and assigns it a PRIMARY KEY automaticaly \n",
    "        quote_id = db['quotes'].insert({ \n",
    "            'text' : quote_text,\n",
    "            'author' : quote_author_url })\n",
    "        #dataset creates a table quote_tags and inserts a list of tags\n",
    "        db['quote_tags'].insert_many([{\n",
    "            'quote_id' : quote_id, \n",
    "            'tag_id' : tag} for tag in quote_tag_urls])\n",
    "\n",
    "def clean_url(url):\n",
    "    # Clean '/author/Steve-Martin' to 'Steve-Martin'\n",
    "    # Use urljoin to make an absolute URL\n",
    "    url = urljoin(base_url, url) # (http://quotes.toscrape.com/,/author/Albert-Einstein/) -> http://quotes.toscrape.com/author/Albert-Einstein/\n",
    "    # Use urlparse to get out the path part\n",
    "    path = urlparse(url).path #returns path after base url \n",
    "    # Now split the path by '/' \n",
    "    # split return list ['', 'author', 'Steve-Martin'] and get the second part\n",
    "    return path.split('/')[2]\n",
    "\n",
    "def scrape_author(html_soup, author_id):\n",
    "    author_name = html_soup.find(class_='author-title').get_text(strip=True)\n",
    "    author_born_date = html_soup.find(class_='author-born-date').get_text(strip=True)\n",
    "    author_born_loc = html_soup.find(class_='author-born-location').get_text(strip=True)\n",
    "    author_desc = html_soup.find(class_='author-description').get_text(strip=True)\n",
    "    db['authors'].insert({ \n",
    "'author_id' : author_id,\n",
    "'name' : author_name,\n",
    "'born_date' : author_born_date,\n",
    "'born_location' : author_born_loc,\n",
    "'description' : author_desc})\n",
    "\n",
    "base_url = 'http://quotes.toscrape.com/'\n",
    "# Start by scraping all the quote pages\n",
    "url = base_url\n",
    "while True:\n",
    "    print('Now scraping page:', url)\n",
    "    r = requests.get(url)\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # Scrape the quotes\n",
    "    scrape_quotes(html_soup)\n",
    "\n",
    "    # Is there a next page?\n",
    "    next_a = html_soup.select('li.next > a')\n",
    "    if not next_a or not next_a[0].get('href'):break\n",
    "    url = urljoin(url, next_a[0].get('href'))\n",
    "\n",
    "# Now fetch out the author information\n",
    "for author_id in authors_seen:\n",
    "    url = urljoin(base_url, '/author/' + author_id)\n",
    "    print('Now scraping author:', url)\n",
    "    r = requests.get(url)\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # Scrape the author information\n",
    "    scrape_author(html_soup, author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'author', 'Steve-Martin']\n"
     ]
    }
   ],
   "source": [
    "str='/author/Steve-Martin'\n",
    "print(str.split('/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61abb1faae53f79e806d9c12619482227edf26d7ba3168cb9b69b001ff4947ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
