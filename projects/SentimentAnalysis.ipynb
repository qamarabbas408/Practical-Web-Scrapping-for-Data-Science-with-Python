{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sentiment Analysis</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part1</h3>\n",
    "We’ll use a book with plenty of reviews, say Learning Python by Mark Lutz, which can be\n",
    "found at <a>https://www.amazon.com/Learning-Python-5th-Mark-Lutz/dp/1449355730/</a>. Note that this\n",
    "product has an id of “1449355730,” and even using the URL <a>https://www.amazon.com/\n",
    "product-reviews/1449355730/</a>, without the product name, will work.<br>\n",
    "If you explore the reviews page, you’ll note that the reviews are paginated. By\n",
    "browsing to other pages and following along in your browser’s developer tools, we see\n",
    "that POST requests are being made (by JavaScript) to URLs looking like <a>https://www.\n",
    "amazon.com/ss/customer-reviews/ajax/reviews/get/ref=cm_cr_arp_d_paging_\n",
    "btm_2</a> with the product id included in the form data, as well as some other form fields\n",
    "that look relatively easy to spoof\n",
    "<img src='images/c1.jpg'><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "review_url = 'https://www.amazon.com/hz/reviews-render/ajax/reviews/get/'\n",
    "product_id = '1449355730'\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 ' + ' (KHTML, like Gecko) Chrome/62.0.3202.62 Safari/537.36'\n",
    "})\n",
    "session.get('https://www.amazon.com/product-reviews/{}/'.format(product_id))\n",
    "def get_reviews(product_id, page):\n",
    "    data = {\n",
    "    'sortBy':'',\n",
    "    'reviewerType':'all_reviews',\n",
    "    'formatType':'',\n",
    "    'mediaType':'',\n",
    "    'filterByStar':'',\n",
    "    'pageNumber':page,\n",
    "    'filterByLanguage':'',\n",
    "    'filterByKeyword':'',\n",
    "    'shouldAppend':'undefined',\n",
    "    'deviceType':'desktop',\n",
    "    'canShowIntHeader':'undefined',\n",
    "    'reftag':'cm_cr_getr_d_paging_btm_prev_{}'.format(page),\n",
    "    'pageSize':10,\n",
    "    'asin':product_id,\n",
    "    'scope':'reviewsAjax1'\n",
    "    }\n",
    "    r = session.post(review_url + 'ref=' + data['reftag'], data=data)\n",
    "    return r.text\n",
    "print(get_reviews(product_id, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the reviews page in the browser, you’ll\n",
    "see that the value of this field is in fact increased for each request, that is, “reviewsAjax1,”\n",
    "“reviewsAjax2,” and so on.Finally, note that the POST request does not return a full HTML page, but some kind\n",
    "of hand-encoded result that will be parsed (normally) by JavaScript: <img src='images/c2.jpg'> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 2</h3>\n",
    "Let’s adjust our code to parse the reviews in a structured format. We’ll loop through\n",
    "all the instructions; convert them using the “json” module; check for “append” entries;\n",
    "and then use Beautiful Soup to parse the HTML fragment and get the review id, rating,title, and text. We’ll also need a small regular expression to get out the rating, which is set\n",
    "as a class with a value like “a-start-1” to “a-star-5”. We could use these as is, but simply\n",
    "getting “1” to “5” might be easier to work with later on, so we already perform a bit of\n",
    "cleaning here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5 Check out the Index R175ZF0CZU718Q\n",
      " - 5 Outstanding introduction to the Python language! R3GM7E8ZWH3TKS\n",
      " - 5 Great Service from the book seller R1XW780574N11X\n",
      " - 5 The book is long because it's thorough, and it's a quality book RUR7PRSM2BZC\n",
      " - 5 huge but well worth it R2KY62EVDQ9636\n",
      " - 5 A Mark Lutz Trifecta of Python Winners R16F2OE9239BC\n",
      " - 5 Comprehensive R36KASBOZZBOK9\n",
      " - 3 Too many words RSX92UJ62C6SF\n",
      " - 3 Half python-proselytizing, half real material R1F9L3BP2EW3VE\n",
      " - 4 A solid introduction to a fun language RSNM1C0OA575D\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "review_url = 'https://www.amazon.com/hz/reviews-render/ajax/reviews/get/'\n",
    "product_id = '1449355730'\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 ' + ' (KHTML, like Gecko) Chrome/62.0.3202.62 Safari/537.36'\n",
    "})\n",
    "session.get('https://www.amazon.com/product-reviews/{}/'.format(product_id))\n",
    "\n",
    "\n",
    "def parse_reviews(reply):\n",
    "    reviews = []\n",
    "    for fragment in reply.split('&&&'):\n",
    "        if not fragment.strip():\n",
    "            continue\n",
    "        json_fragment = json.loads(fragment)\n",
    "        if json_fragment[0] != 'append':\n",
    "            continue\n",
    "        html_soup = BeautifulSoup(json_fragment[2], 'html.parser')\n",
    "        div = html_soup.find('div', class_='review')\n",
    "        if not div:\n",
    "            continue\n",
    "        review_id = div.get('id')\n",
    "        title = html_soup.find(class_='review-title').get_text(strip=True)\n",
    "        review = html_soup.find(class_='review-text').get_text(strip=True)\n",
    "\n",
    "        # Find and clean the rating:\n",
    "        review_cls = ' '.join(html_soup.find(class_='review-rating').get('class'))\n",
    "        rating = re.search('a-star-(\\d+)', review_cls).group(1)\n",
    "        reviews.append({\n",
    "            'review_id': review_id,\n",
    "            'rating': rating,\n",
    "            'title': title,\n",
    "            'review': review})\n",
    "    return reviews\n",
    "\n",
    "def get_reviews(product_id, page):\n",
    "    data = {\n",
    "    'sortBy':'',\n",
    "    'reviewerType':'all_reviews',\n",
    "    'formatType':'',\n",
    "    'mediaType':'',\n",
    "    'filterByStar':'',\n",
    "    'pageNumber':page,\n",
    "    'filterByLanguage':'',\n",
    "    'filterByKeyword':'',\n",
    "    'shouldAppend':'undefined',\n",
    "    'deviceType':'desktop',\n",
    "    'canShowIntHeader':'undefined',\n",
    "    'reftag':'cm_cr_getr_d_paging_btm_prev_{}'.format(page),\n",
    "    'pageSize':10,\n",
    "    'asin':product_id,\n",
    "    'scope':'reviewsAjax1'\n",
    "    }\n",
    "    r = session.post(review_url + 'ref=' + data['reftag'], data=data)\n",
    "    reviews = parse_reviews(r.text)\n",
    "    return reviews\n",
    "reviews=get_reviews(product_id, 1) \n",
    "for review in reviews:\n",
    "    print(' -', review['rating'], review['title'],review['review_id'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 3</h3>\n",
    "The only thing left to do is to loop through all the pages, and store the\n",
    "reviews in a database using the “dataset” library. Luckily, figuring out when to stop\n",
    "looping is easy: once we do not get any reviews for a particular page, we can stop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping:  1\n",
      " - 5 Check out the Index R175ZF0CZU718Q\n",
      " - 5 Outstanding introduction to the Python language! R3GM7E8ZWH3TKS\n",
      " - 5 Great Service from the book seller R1XW780574N11X\n",
      " - 5 The book is long because it's thorough, and it's a quality book RUR7PRSM2BZC\n",
      " - 5 huge but well worth it R2KY62EVDQ9636\n",
      " - 5 A Mark Lutz Trifecta of Python Winners R16F2OE9239BC\n",
      " - 5 Comprehensive R36KASBOZZBOK9\n",
      " - 3 Too many words RSX92UJ62C6SF\n",
      " - 3 Half python-proselytizing, half real material R1F9L3BP2EW3VE\n",
      " - 4 A solid introduction to a fun language RSNM1C0OA575D\n",
      "Scraping:  2\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mScraping: \u001b[39m\u001b[39m'\u001b[39m,page)\n\u001b[1;32m---> 68\u001b[0m     reviews\u001b[39m=\u001b[39mget_reviews(product_id, page) \n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reviews: \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[39mfor\u001b[39;00m review \u001b[39min\u001b[39;00m reviews:\n",
      "Cell \u001b[1;32mIn [4], line 63\u001b[0m, in \u001b[0;36mget_reviews\u001b[1;34m(product_id, page)\u001b[0m\n\u001b[0;32m     45\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     46\u001b[0m \u001b[39m'\u001b[39m\u001b[39msortBy\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     47\u001b[0m \u001b[39m'\u001b[39m\u001b[39mreviewerType\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mall_reviews\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m'\u001b[39m\u001b[39mscope\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mreviewsAjax1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     61\u001b[0m }\n\u001b[0;32m     62\u001b[0m r \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mpost(review_url \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mref=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mreftag\u001b[39m\u001b[39m'\u001b[39m], data\u001b[39m=\u001b[39mdata)\n\u001b[1;32m---> 63\u001b[0m reviews \u001b[39m=\u001b[39m parse_reviews(r\u001b[39m.\u001b[39;49mtext)\n\u001b[0;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m reviews\n",
      "Cell \u001b[1;32mIn [4], line 23\u001b[0m, in \u001b[0;36mparse_reviews\u001b[1;34m(reply)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fragment\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     22\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m json_fragment \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(fragment)\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m json_fragment[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Qamar Abbas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Qamar Abbas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Qamar Abbas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import dataset\n",
    "\n",
    "db = dataset.connect('sqlite:///reviews.db')\n",
    "\n",
    "review_url = 'https://www.amazon.com/hz/reviews-render/ajax/reviews/get/'\n",
    "product_id = '1449355730'\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 ' + ' (KHTML, like Gecko) Chrome/62.0.3202.62 Safari/537.36'\n",
    "})\n",
    "session.get('https://www.amazon.com/product-reviews/{}/'.format(product_id))\n",
    "\n",
    "\n",
    "def parse_reviews(reply):\n",
    "    reviews = []\n",
    "    for fragment in reply.split('&&&'):\n",
    "        if not fragment.strip():\n",
    "            continue\n",
    "        json_fragment = json.loads(fragment)\n",
    "        if json_fragment[0] != 'append':\n",
    "            continue\n",
    "        html_soup = BeautifulSoup(json_fragment[2], 'html.parser')\n",
    "        div = html_soup.find('div', class_='review')\n",
    "        if not div:\n",
    "            continue\n",
    "        review_id = div.get('id')\n",
    "        title = html_soup.find(class_='review-title').get_text(strip=True)\n",
    "        review = html_soup.find(class_='review-text').get_text(strip=True)\n",
    "\n",
    "        # Find and clean the rating:\n",
    "        review_cls = ' '.join(html_soup.find(class_='review-rating').get('class'))\n",
    "        rating = re.search('a-star-(\\d+)', review_cls).group(1)\n",
    "        reviews.append({\n",
    "            'review_id': review_id,\n",
    "            'rating': rating,\n",
    "            'title': title,\n",
    "            'review': review})\n",
    "    return reviews\n",
    "\n",
    "def get_reviews(product_id, page):\n",
    "    data = {\n",
    "    'sortBy':'',\n",
    "    'reviewerType':'all_reviews',\n",
    "    'formatType':'',\n",
    "    'mediaType':'',\n",
    "    'filterByStar':'',\n",
    "    'pageNumber':page,\n",
    "    'filterByLanguage':'',\n",
    "    'filterByKeyword':'',\n",
    "    'shouldAppend':'undefined',\n",
    "    'deviceType':'desktop',\n",
    "    'canShowIntHeader':'undefined',\n",
    "    'reftag':'cm_cr_getr_d_paging_btm_prev_{}'.format(page),\n",
    "    'pageSize':10,\n",
    "    'asin':product_id,\n",
    "    'scope':'reviewsAjax1'\n",
    "    }\n",
    "    r = session.post(review_url + 'ref=' + data['reftag'], data=data)\n",
    "    reviews = parse_reviews(r.text)\n",
    "    return reviews\n",
    "page=1\n",
    "while True:\n",
    "    print('Scraping: ',page)\n",
    "    reviews=get_reviews(product_id, page) \n",
    "    if not reviews: break\n",
    "    for review in reviews:\n",
    "        print(' -', review['rating'], review['title'],review['review_id'])\n",
    "        db['reviews'].upsert(review, ['review_id'])\n",
    "    page+=1    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61abb1faae53f79e806d9c12619482227edf26d7ba3168cb9b69b001ff4947ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
